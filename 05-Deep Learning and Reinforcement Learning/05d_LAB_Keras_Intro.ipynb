{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>12</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.497</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>8</td>\n",
       "      <td>181</td>\n",
       "      <td>68</td>\n",
       "      <td>36</td>\n",
       "      <td>495</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.615</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.695</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9</td>\n",
       "      <td>123</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>94</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.374</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "582              12                     121              78              17   \n",
       "563               6                      99              60              19   \n",
       "186               8                     181              68              36   \n",
       "640               0                     102              86              17   \n",
       "191               9                     123              70              44   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "582        0  26.5              0.259   62             0  \n",
       "563       54  26.9              0.497   32             0  \n",
       "186      495  30.1              0.615   60             1  \n",
       "640      105  29.3              0.695   27             0  \n",
       "191       94  33.1              0.374   40             0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.781\n",
      "roc-auc is 0.837\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(units = 12, input_shape = (8,), activation = 'sigmoid'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0445 - accuracy: 0.3455 - val_loss: 1.0146 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0060 - accuracy: 0.3455 - val_loss: 0.9793 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9706 - accuracy: 0.3455 - val_loss: 0.9470 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9382 - accuracy: 0.3455 - val_loss: 0.9175 - val_accuracy: 0.3594\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9086 - accuracy: 0.3455 - val_loss: 0.8906 - val_accuracy: 0.3594\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8817 - accuracy: 0.3455 - val_loss: 0.8663 - val_accuracy: 0.3594\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8573 - accuracy: 0.3455 - val_loss: 0.8442 - val_accuracy: 0.3594\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8352 - accuracy: 0.3455 - val_loss: 0.8243 - val_accuracy: 0.3594\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8152 - accuracy: 0.3472 - val_loss: 0.8063 - val_accuracy: 0.3594\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7972 - accuracy: 0.3490 - val_loss: 0.7901 - val_accuracy: 0.3542\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.3507 - val_loss: 0.7755 - val_accuracy: 0.3281\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7663 - accuracy: 0.3438 - val_loss: 0.7625 - val_accuracy: 0.3281\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7532 - accuracy: 0.3455 - val_loss: 0.7507 - val_accuracy: 0.3177\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.3507 - val_loss: 0.7401 - val_accuracy: 0.3125\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.3559 - val_loss: 0.7306 - val_accuracy: 0.3021\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.3542 - val_loss: 0.7221 - val_accuracy: 0.3281\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.3924 - val_loss: 0.7144 - val_accuracy: 0.3542\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.4236 - val_loss: 0.7075 - val_accuracy: 0.3906\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.4601 - val_loss: 0.7014 - val_accuracy: 0.4896\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5226 - val_loss: 0.6958 - val_accuracy: 0.5260\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5521 - val_loss: 0.6908 - val_accuracy: 0.5833\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.6007 - val_loss: 0.6863 - val_accuracy: 0.6146\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.6215 - val_loss: 0.6822 - val_accuracy: 0.6302\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.6528 - val_loss: 0.6785 - val_accuracy: 0.6302\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6615 - val_loss: 0.6752 - val_accuracy: 0.6458\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6615 - val_loss: 0.6721 - val_accuracy: 0.6510\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6597 - val_loss: 0.6694 - val_accuracy: 0.6615\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.6580 - val_loss: 0.6669 - val_accuracy: 0.6458\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6545 - val_loss: 0.6647 - val_accuracy: 0.6510\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6580 - val_loss: 0.6626 - val_accuracy: 0.6562\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6562 - val_loss: 0.6607 - val_accuracy: 0.6562\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6562 - val_loss: 0.6590 - val_accuracy: 0.6510\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6562 - val_loss: 0.6574 - val_accuracy: 0.6458\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6562 - val_loss: 0.6560 - val_accuracy: 0.6458\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6562 - val_loss: 0.6546 - val_accuracy: 0.6458\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6562 - val_loss: 0.6534 - val_accuracy: 0.6458\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6562 - val_loss: 0.6523 - val_accuracy: 0.6458\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6545 - val_loss: 0.6512 - val_accuracy: 0.6458\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6545 - val_loss: 0.6502 - val_accuracy: 0.6458\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6545 - val_loss: 0.6493 - val_accuracy: 0.6458\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6545 - val_loss: 0.6484 - val_accuracy: 0.6406\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6545 - val_loss: 0.6476 - val_accuracy: 0.6406\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6545 - val_loss: 0.6468 - val_accuracy: 0.6406\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6545 - val_loss: 0.6461 - val_accuracy: 0.6406\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6545 - val_loss: 0.6454 - val_accuracy: 0.6406\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6545 - val_loss: 0.6447 - val_accuracy: 0.6406\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6545 - val_loss: 0.6441 - val_accuracy: 0.6406\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6545 - val_loss: 0.6435 - val_accuracy: 0.6406\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6545 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6545 - val_loss: 0.6424 - val_accuracy: 0.6406\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6545 - val_loss: 0.6418 - val_accuracy: 0.6406\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6545 - val_loss: 0.6413 - val_accuracy: 0.6406\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6545 - val_loss: 0.6408 - val_accuracy: 0.6406\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6545 - val_loss: 0.6403 - val_accuracy: 0.6406\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6545 - val_loss: 0.6399 - val_accuracy: 0.6406\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6545 - val_loss: 0.6394 - val_accuracy: 0.6406\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6545 - val_loss: 0.6389 - val_accuracy: 0.6406\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6545 - val_loss: 0.6385 - val_accuracy: 0.6406\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6545 - val_loss: 0.6381 - val_accuracy: 0.6406\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6545 - val_loss: 0.6376 - val_accuracy: 0.6406\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6545 - val_loss: 0.6372 - val_accuracy: 0.6406\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6545 - val_loss: 0.6368 - val_accuracy: 0.6406\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6545 - val_loss: 0.6364 - val_accuracy: 0.6406\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6545 - val_loss: 0.6360 - val_accuracy: 0.6406\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6545 - val_loss: 0.6356 - val_accuracy: 0.6406\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6545 - val_loss: 0.6352 - val_accuracy: 0.6406\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6545 - val_loss: 0.6348 - val_accuracy: 0.6406\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6545 - val_loss: 0.6344 - val_accuracy: 0.6406\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6545 - val_loss: 0.6340 - val_accuracy: 0.6406\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6545 - val_loss: 0.6336 - val_accuracy: 0.6406\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6545 - val_loss: 0.6333 - val_accuracy: 0.6406\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6545 - val_loss: 0.6329 - val_accuracy: 0.6406\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6545 - val_loss: 0.6325 - val_accuracy: 0.6406\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6545 - val_loss: 0.6321 - val_accuracy: 0.6406\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6545 - val_loss: 0.6318 - val_accuracy: 0.6406\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6545 - val_loss: 0.6314 - val_accuracy: 0.6406\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6545 - val_loss: 0.6310 - val_accuracy: 0.6406\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6545 - val_loss: 0.6307 - val_accuracy: 0.6406\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6545 - val_loss: 0.6303 - val_accuracy: 0.6406\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6545 - val_loss: 0.6299 - val_accuracy: 0.6406\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6545 - val_loss: 0.6296 - val_accuracy: 0.6406\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6545 - val_loss: 0.6292 - val_accuracy: 0.6406\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6545 - val_loss: 0.6288 - val_accuracy: 0.6406\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6545 - val_loss: 0.6285 - val_accuracy: 0.6406\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6545 - val_loss: 0.6281 - val_accuracy: 0.6406\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6545 - val_loss: 0.6278 - val_accuracy: 0.6406\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6545 - val_loss: 0.6274 - val_accuracy: 0.6406\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6545 - val_loss: 0.6270 - val_accuracy: 0.6406\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6545 - val_loss: 0.6267 - val_accuracy: 0.6406\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6545 - val_loss: 0.6263 - val_accuracy: 0.6406\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6545 - val_loss: 0.6260 - val_accuracy: 0.6406\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6545 - val_loss: 0.6256 - val_accuracy: 0.6406\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6545 - val_loss: 0.6252 - val_accuracy: 0.6406\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6545 - val_loss: 0.6249 - val_accuracy: 0.6406\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6545 - val_loss: 0.6245 - val_accuracy: 0.6406\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6545 - val_loss: 0.6242 - val_accuracy: 0.6406\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6545 - val_loss: 0.6238 - val_accuracy: 0.6406\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6545 - val_loss: 0.6235 - val_accuracy: 0.6406\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6545 - val_loss: 0.6231 - val_accuracy: 0.6406\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6545 - val_loss: 0.6227 - val_accuracy: 0.6406\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6545 - val_loss: 0.6224 - val_accuracy: 0.6406\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6545 - val_loss: 0.6220 - val_accuracy: 0.6406\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6545 - val_loss: 0.6217 - val_accuracy: 0.6406\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6545 - val_loss: 0.6213 - val_accuracy: 0.6406\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6545 - val_loss: 0.6210 - val_accuracy: 0.6406\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6545 - val_loss: 0.6206 - val_accuracy: 0.6406\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6545 - val_loss: 0.6203 - val_accuracy: 0.6406\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6545 - val_loss: 0.6199 - val_accuracy: 0.6406\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.6545 - val_loss: 0.6196 - val_accuracy: 0.6406\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6545 - val_loss: 0.6192 - val_accuracy: 0.6406\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6545 - val_loss: 0.6189 - val_accuracy: 0.6406\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6545 - val_loss: 0.6185 - val_accuracy: 0.6406\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6545 - val_loss: 0.6181 - val_accuracy: 0.6406\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6545 - val_loss: 0.6178 - val_accuracy: 0.6406\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6545 - val_loss: 0.6174 - val_accuracy: 0.6406\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6545 - val_loss: 0.6171 - val_accuracy: 0.6458\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6545 - val_loss: 0.6167 - val_accuracy: 0.6458\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6545 - val_loss: 0.6164 - val_accuracy: 0.6458\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.6545 - val_loss: 0.6160 - val_accuracy: 0.6458\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6545 - val_loss: 0.6157 - val_accuracy: 0.6458\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.6545 - val_loss: 0.6153 - val_accuracy: 0.6458\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6545 - val_loss: 0.6150 - val_accuracy: 0.6458\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6545 - val_loss: 0.6146 - val_accuracy: 0.6458\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6545 - val_loss: 0.6143 - val_accuracy: 0.6458\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6545 - val_loss: 0.6139 - val_accuracy: 0.6458\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6545 - val_loss: 0.6136 - val_accuracy: 0.6458\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6545 - val_loss: 0.6132 - val_accuracy: 0.6458\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6545 - val_loss: 0.6129 - val_accuracy: 0.6458\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6545 - val_loss: 0.6125 - val_accuracy: 0.6458\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6545 - val_loss: 0.6122 - val_accuracy: 0.6458\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6545 - val_loss: 0.6118 - val_accuracy: 0.6458\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6545 - val_loss: 0.6115 - val_accuracy: 0.6458\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6545 - val_loss: 0.6111 - val_accuracy: 0.6458\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6545 - val_loss: 0.6108 - val_accuracy: 0.6458\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6545 - val_loss: 0.6104 - val_accuracy: 0.6458\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.6545 - val_loss: 0.6101 - val_accuracy: 0.6458\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6545 - val_loss: 0.6098 - val_accuracy: 0.6458\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6562 - val_loss: 0.6094 - val_accuracy: 0.6458\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6562 - val_loss: 0.6091 - val_accuracy: 0.6458\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6562 - val_loss: 0.6087 - val_accuracy: 0.6458\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6562 - val_loss: 0.6084 - val_accuracy: 0.6458\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6562 - val_loss: 0.6080 - val_accuracy: 0.6458\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6562 - val_loss: 0.6077 - val_accuracy: 0.6458\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6562 - val_loss: 0.6073 - val_accuracy: 0.6458\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.6562 - val_loss: 0.6070 - val_accuracy: 0.6458\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6562 - val_loss: 0.6066 - val_accuracy: 0.6458\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6580 - val_loss: 0.6063 - val_accuracy: 0.6458\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6580 - val_loss: 0.6059 - val_accuracy: 0.6458\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6580 - val_loss: 0.6056 - val_accuracy: 0.6458\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6580 - val_loss: 0.6052 - val_accuracy: 0.6458\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6580 - val_loss: 0.6049 - val_accuracy: 0.6458\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6580 - val_loss: 0.6046 - val_accuracy: 0.6458\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6580 - val_loss: 0.6042 - val_accuracy: 0.6458\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6580 - val_loss: 0.6039 - val_accuracy: 0.6458\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.6580 - val_loss: 0.6035 - val_accuracy: 0.6458\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6580 - val_loss: 0.6032 - val_accuracy: 0.6458\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6580 - val_loss: 0.6028 - val_accuracy: 0.6458\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6580 - val_loss: 0.6025 - val_accuracy: 0.6458\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6580 - val_loss: 0.6021 - val_accuracy: 0.6458\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6580 - val_loss: 0.6018 - val_accuracy: 0.6458\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6580 - val_loss: 0.6015 - val_accuracy: 0.6458\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6580 - val_loss: 0.6011 - val_accuracy: 0.6458\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6580 - val_loss: 0.6008 - val_accuracy: 0.6510\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6580 - val_loss: 0.6004 - val_accuracy: 0.6510\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6580 - val_loss: 0.6001 - val_accuracy: 0.6510\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6580 - val_loss: 0.5997 - val_accuracy: 0.6510\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6580 - val_loss: 0.5994 - val_accuracy: 0.6510\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6580 - val_loss: 0.5990 - val_accuracy: 0.6510\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6580 - val_loss: 0.5987 - val_accuracy: 0.6510\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6597 - val_loss: 0.5984 - val_accuracy: 0.6510\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.6597 - val_loss: 0.5980 - val_accuracy: 0.6510\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.6597 - val_loss: 0.5977 - val_accuracy: 0.6562\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.6597 - val_loss: 0.5973 - val_accuracy: 0.6615\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6597 - val_loss: 0.5970 - val_accuracy: 0.6667\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6632 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6632 - val_loss: 0.5963 - val_accuracy: 0.6667\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6632 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6632 - val_loss: 0.5956 - val_accuracy: 0.6667\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6632 - val_loss: 0.5953 - val_accuracy: 0.6667\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6649 - val_loss: 0.5950 - val_accuracy: 0.6667\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.6649 - val_loss: 0.5946 - val_accuracy: 0.6667\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6649 - val_loss: 0.5943 - val_accuracy: 0.6667\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.6649 - val_loss: 0.5939 - val_accuracy: 0.6667\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6667 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6684 - val_loss: 0.5933 - val_accuracy: 0.6667\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6684 - val_loss: 0.5929 - val_accuracy: 0.6667\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.6684 - val_loss: 0.5926 - val_accuracy: 0.6667\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6684 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6684 - val_loss: 0.5919 - val_accuracy: 0.6667\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.6684 - val_loss: 0.5916 - val_accuracy: 0.6667\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6684 - val_loss: 0.5912 - val_accuracy: 0.6719\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6701 - val_loss: 0.5909 - val_accuracy: 0.6719\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.6701 - val_loss: 0.5906 - val_accuracy: 0.6719\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6684 - val_loss: 0.5902 - val_accuracy: 0.6719\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6684 - val_loss: 0.5899 - val_accuracy: 0.6719\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.6684 - val_loss: 0.5895 - val_accuracy: 0.6719\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6701 - val_loss: 0.5892 - val_accuracy: 0.6719\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.6701 - val_loss: 0.5889 - val_accuracy: 0.6719\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6701 - val_loss: 0.5885 - val_accuracy: 0.6719\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.6701 - val_loss: 0.5882 - val_accuracy: 0.6719\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37547344],\n",
       "       [0.45272195],\n",
       "       [0.32866374],\n",
       "       [0.28875974],\n",
       "       [0.28855604],\n",
       "       [0.39777717],\n",
       "       [0.24575232],\n",
       "       [0.32347262],\n",
       "       [0.52436125],\n",
       "       [0.29531503]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.672\n",
      "roc-auc is 0.788\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f814ed10b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.6701 - val_loss: 0.5879 - val_accuracy: 0.6719\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6701 - val_loss: 0.5875 - val_accuracy: 0.6719\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.6701 - val_loss: 0.5872 - val_accuracy: 0.6719\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.6684 - val_loss: 0.5869 - val_accuracy: 0.6719\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.6684 - val_loss: 0.5865 - val_accuracy: 0.6719\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6684 - val_loss: 0.5862 - val_accuracy: 0.6771\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.6684 - val_loss: 0.5859 - val_accuracy: 0.6771\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6684 - val_loss: 0.5855 - val_accuracy: 0.6771\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.6701 - val_loss: 0.5852 - val_accuracy: 0.6771\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.6701 - val_loss: 0.5849 - val_accuracy: 0.6771\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.6701 - val_loss: 0.5845 - val_accuracy: 0.6771\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.6701 - val_loss: 0.5842 - val_accuracy: 0.6719\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6701 - val_loss: 0.5839 - val_accuracy: 0.6719\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.6667 - val_loss: 0.5835 - val_accuracy: 0.6719\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.6684 - val_loss: 0.5832 - val_accuracy: 0.6719\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.6684 - val_loss: 0.5829 - val_accuracy: 0.6719\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.6684 - val_loss: 0.5825 - val_accuracy: 0.6719\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.6701 - val_loss: 0.5822 - val_accuracy: 0.6719\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.6701 - val_loss: 0.5819 - val_accuracy: 0.6719\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.6701 - val_loss: 0.5815 - val_accuracy: 0.6719\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.6719 - val_loss: 0.5812 - val_accuracy: 0.6719\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.6719 - val_loss: 0.5809 - val_accuracy: 0.6719\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.6719 - val_loss: 0.5806 - val_accuracy: 0.6719\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.6719 - val_loss: 0.5802 - val_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.6736 - val_loss: 0.5799 - val_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.6736 - val_loss: 0.5796 - val_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.6736 - val_loss: 0.5792 - val_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.6736 - val_loss: 0.5789 - val_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.6736 - val_loss: 0.5786 - val_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.6736 - val_loss: 0.5783 - val_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.6736 - val_loss: 0.5779 - val_accuracy: 0.6719\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.6736 - val_loss: 0.5776 - val_accuracy: 0.6719\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.6736 - val_loss: 0.5773 - val_accuracy: 0.6719\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6753 - val_loss: 0.5770 - val_accuracy: 0.6719\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.6753 - val_loss: 0.5766 - val_accuracy: 0.6719\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.6753 - val_loss: 0.5763 - val_accuracy: 0.6719\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.6771 - val_loss: 0.5760 - val_accuracy: 0.6719\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.6771 - val_loss: 0.5757 - val_accuracy: 0.6719\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.6771 - val_loss: 0.5753 - val_accuracy: 0.6719\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.6753 - val_loss: 0.5750 - val_accuracy: 0.6719\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.6771 - val_loss: 0.5747 - val_accuracy: 0.6719\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.6771 - val_loss: 0.5744 - val_accuracy: 0.6771\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.6788 - val_loss: 0.5741 - val_accuracy: 0.6771\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.6788 - val_loss: 0.5737 - val_accuracy: 0.6823\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.6788 - val_loss: 0.5734 - val_accuracy: 0.6823\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.6788 - val_loss: 0.5731 - val_accuracy: 0.6823\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.6788 - val_loss: 0.5728 - val_accuracy: 0.6823\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.6788 - val_loss: 0.5725 - val_accuracy: 0.6823\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.6806 - val_loss: 0.5721 - val_accuracy: 0.6823\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.6806 - val_loss: 0.5718 - val_accuracy: 0.6823\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.6806 - val_loss: 0.5715 - val_accuracy: 0.6823\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.6806 - val_loss: 0.5712 - val_accuracy: 0.6823\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.6806 - val_loss: 0.5709 - val_accuracy: 0.6771\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.6806 - val_loss: 0.5706 - val_accuracy: 0.6771\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.6806 - val_loss: 0.5703 - val_accuracy: 0.6771\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.6823 - val_loss: 0.5699 - val_accuracy: 0.6771\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.6823 - val_loss: 0.5696 - val_accuracy: 0.6771\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.6823 - val_loss: 0.5693 - val_accuracy: 0.6771\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.6858 - val_loss: 0.5690 - val_accuracy: 0.6771\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.6858 - val_loss: 0.5687 - val_accuracy: 0.6823\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.6875 - val_loss: 0.5684 - val_accuracy: 0.6823\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.6892 - val_loss: 0.5681 - val_accuracy: 0.6823\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.6910 - val_loss: 0.5677 - val_accuracy: 0.6823\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.6910 - val_loss: 0.5674 - val_accuracy: 0.6823\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.6910 - val_loss: 0.5671 - val_accuracy: 0.6823\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.6927 - val_loss: 0.5668 - val_accuracy: 0.6875\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.6944 - val_loss: 0.5665 - val_accuracy: 0.6875\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.6944 - val_loss: 0.5662 - val_accuracy: 0.6875\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.6962 - val_loss: 0.5659 - val_accuracy: 0.6823\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.6962 - val_loss: 0.5656 - val_accuracy: 0.6823\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.6944 - val_loss: 0.5653 - val_accuracy: 0.6823\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.6962 - val_loss: 0.5650 - val_accuracy: 0.6823\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.6944 - val_loss: 0.5647 - val_accuracy: 0.6875\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.6962 - val_loss: 0.5644 - val_accuracy: 0.6875\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.6944 - val_loss: 0.5641 - val_accuracy: 0.6875\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.6944 - val_loss: 0.5638 - val_accuracy: 0.6875\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.6944 - val_loss: 0.5634 - val_accuracy: 0.6875\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.6944 - val_loss: 0.5631 - val_accuracy: 0.6875\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.6944 - val_loss: 0.5628 - val_accuracy: 0.6927\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.6944 - val_loss: 0.5625 - val_accuracy: 0.6927\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.6944 - val_loss: 0.5622 - val_accuracy: 0.6927\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.6944 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.6962 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.6962 - val_loss: 0.5613 - val_accuracy: 0.6979\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.6979 - val_loss: 0.5610 - val_accuracy: 0.7031\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.6979 - val_loss: 0.5607 - val_accuracy: 0.7031\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.6979 - val_loss: 0.5604 - val_accuracy: 0.7031\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.6979 - val_loss: 0.5601 - val_accuracy: 0.7031\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.6979 - val_loss: 0.5599 - val_accuracy: 0.7031\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.6997 - val_loss: 0.5596 - val_accuracy: 0.7031\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7014 - val_loss: 0.5593 - val_accuracy: 0.7031\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7014 - val_loss: 0.5590 - val_accuracy: 0.7031\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7014 - val_loss: 0.5587 - val_accuracy: 0.7031\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7031 - val_loss: 0.5584 - val_accuracy: 0.7031\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7066 - val_loss: 0.5581 - val_accuracy: 0.7031\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7083 - val_loss: 0.5578 - val_accuracy: 0.7031\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7118 - val_loss: 0.5575 - val_accuracy: 0.7135\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7118 - val_loss: 0.5572 - val_accuracy: 0.7135\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7118 - val_loss: 0.5569 - val_accuracy: 0.7135\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7118 - val_loss: 0.5566 - val_accuracy: 0.7135\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7118 - val_loss: 0.5563 - val_accuracy: 0.7135\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7118 - val_loss: 0.5561 - val_accuracy: 0.7135\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7118 - val_loss: 0.5558 - val_accuracy: 0.7135\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7118 - val_loss: 0.5555 - val_accuracy: 0.7135\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7135 - val_loss: 0.5552 - val_accuracy: 0.7135\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7153 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7153 - val_loss: 0.5546 - val_accuracy: 0.7135\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7153 - val_loss: 0.5543 - val_accuracy: 0.7135\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7170 - val_loss: 0.5541 - val_accuracy: 0.7135\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7170 - val_loss: 0.5538 - val_accuracy: 0.7135\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7188 - val_loss: 0.5535 - val_accuracy: 0.7135\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7188 - val_loss: 0.5532 - val_accuracy: 0.7135\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7188 - val_loss: 0.5529 - val_accuracy: 0.7135\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7205 - val_loss: 0.5527 - val_accuracy: 0.7135\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7205 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7205 - val_loss: 0.5521 - val_accuracy: 0.7188\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7240 - val_loss: 0.5518 - val_accuracy: 0.7188\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7240 - val_loss: 0.5515 - val_accuracy: 0.7188\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7240 - val_loss: 0.5513 - val_accuracy: 0.7188\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7222 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7222 - val_loss: 0.5507 - val_accuracy: 0.7188\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7240 - val_loss: 0.5504 - val_accuracy: 0.7188\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7240 - val_loss: 0.5502 - val_accuracy: 0.7188\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7222 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7240 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7257 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7257 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7292 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7292 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7274 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7274 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7274 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7292 - val_loss: 0.5475 - val_accuracy: 0.7396\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7292 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7292 - val_loss: 0.5470 - val_accuracy: 0.7396\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7292 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7292 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7326 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7326 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7326 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7326 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7326 - val_loss: 0.5451 - val_accuracy: 0.7448\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7326 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7344 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7344 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7344 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7361 - val_loss: 0.5438 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7361 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7396 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7396 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7396 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7413 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7431 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7431 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7431 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7448 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7448 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7448 - val_loss: 0.5411 - val_accuracy: 0.7552\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7448 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7448 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7465 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7465 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7465 - val_loss: 0.5399 - val_accuracy: 0.7604\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7483 - val_loss: 0.5396 - val_accuracy: 0.7604\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7483 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7465 - val_loss: 0.5391 - val_accuracy: 0.7604\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7483 - val_loss: 0.5389 - val_accuracy: 0.7604\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7465 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7465 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7465 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7465 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7465 - val_loss: 0.5377 - val_accuracy: 0.7604\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7483 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7483 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7483 - val_loss: 0.5368 - val_accuracy: 0.7604\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7483 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7465 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7483 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7483 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7483 - val_loss: 0.5356 - val_accuracy: 0.7604\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7465 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7465 - val_loss: 0.5352 - val_accuracy: 0.7604\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7448 - val_loss: 0.5350 - val_accuracy: 0.7604\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7448 - val_loss: 0.5347 - val_accuracy: 0.7604\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7431 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7448 - val_loss: 0.5343 - val_accuracy: 0.7604\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7431 - val_loss: 0.5341 - val_accuracy: 0.7604\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7431 - val_loss: 0.5339 - val_accuracy: 0.7604\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7431 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7431 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7448 - val_loss: 0.5332 - val_accuracy: 0.7656\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7431 - val_loss: 0.5330 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7431 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7431 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7431 - val_loss: 0.5323 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7431 - val_loss: 0.5321 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7413 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7413 - val_loss: 0.5317 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7396 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7396 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7413 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7413 - val_loss: 0.5308 - val_accuracy: 0.7656\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7413 - val_loss: 0.5306 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7431 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7431 - val_loss: 0.5302 - val_accuracy: 0.7656\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7431 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7413 - val_loss: 0.5298 - val_accuracy: 0.7604\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7413 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7431 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7431 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7431 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7431 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7431 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7448 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7465 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7448 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7448 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7465 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7483 - val_loss: 0.5272 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7500 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7517 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7500 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7517 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7535 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7535 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7535 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7535 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7569 - val_loss: 0.5255 - val_accuracy: 0.7604\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7569 - val_loss: 0.5253 - val_accuracy: 0.7604\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7569 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7569 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7587 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7587 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7587 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7587 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7587 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7604 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7569 - val_loss: 0.5236 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7587 - val_loss: 0.5234 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7604 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7604 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7604 - val_loss: 0.5227 - val_accuracy: 0.7708\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7604 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7604 - val_loss: 0.5224 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7604 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7604 - val_loss: 0.5220 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7622 - val_loss: 0.5213 - val_accuracy: 0.7708\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7622 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7622 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7622 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7622 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7622 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7622 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7604 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7604 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7604 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7622 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7656 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7656 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7656 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7656 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7656 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7656 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7656 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7656 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7656 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7656 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7656 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7656 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7656 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7656 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7656 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7656 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7656 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7656 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7674 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7674 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7674 - val_loss: 0.5161 - val_accuracy: 0.7708\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7674 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7674 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7691 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7674 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7691 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7691 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7691 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7708 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7691 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7708 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7708 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7708 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7726 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7726 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7726 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7726 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7708 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7708 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7708 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7691 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7691 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7691 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7708 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7708 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7691 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7708 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7708 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7726 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7726 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7726 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7726 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7726 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7726 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7726 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7726 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7726 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7726 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7726 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7726 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7743 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7760 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7760 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7760 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7760 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7760 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7760 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7760 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7743 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7743 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7726 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7726 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7726 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7726 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7726 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7726 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7726 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7726 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7708 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7708 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7708 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7726 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7743 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7743 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7743 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7743 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7743 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7743 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7743 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7743 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7743 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7760 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7743 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7743 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7743 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7743 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7743 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7743 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7743 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7743 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7743 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7743 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7743 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7743 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7760 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7795 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7812 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7847 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7847 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7847 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7847 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7865 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7865 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7847 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7865 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7865 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7865 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7865 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7865 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7865 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7847 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7847 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7847 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7847 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7847 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7830 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7812 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7830 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7830 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7830 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7830 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7830 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7812 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7830 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7830 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7830 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7830 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7830 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7830 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7865 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7830 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7604\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7604\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7604\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7604\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7604\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7604\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7604\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7830 - val_loss: 0.4945 - val_accuracy: 0.7604\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7847 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7847 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7847 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7847 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7847 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7847 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7847 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7830 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7847 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7847 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7847 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7847 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4882 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f8162df3c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7188WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6961 - accuracy: 0.6319 - val_loss: 0.6880 - val_accuracy: 0.6042\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.6441 - val_loss: 0.6844 - val_accuracy: 0.6302\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.6632 - val_loss: 0.6809 - val_accuracy: 0.6354\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.6736 - val_loss: 0.6777 - val_accuracy: 0.6510\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.6875 - val_loss: 0.6747 - val_accuracy: 0.6406\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.6892 - val_loss: 0.6718 - val_accuracy: 0.6510\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6858 - val_loss: 0.6691 - val_accuracy: 0.6615\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6840 - val_loss: 0.6665 - val_accuracy: 0.6615\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.6892 - val_loss: 0.6641 - val_accuracy: 0.6771\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6858 - val_loss: 0.6618 - val_accuracy: 0.6875\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6875 - val_loss: 0.6596 - val_accuracy: 0.6927\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6910 - val_loss: 0.6575 - val_accuracy: 0.6979\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6875 - val_loss: 0.6556 - val_accuracy: 0.7031\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6944 - val_loss: 0.6537 - val_accuracy: 0.7083\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6979 - val_loss: 0.6519 - val_accuracy: 0.7083\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6997 - val_loss: 0.6502 - val_accuracy: 0.7031\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.7014 - val_loss: 0.6485 - val_accuracy: 0.6927\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.7031 - val_loss: 0.6469 - val_accuracy: 0.6875\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.7031 - val_loss: 0.6454 - val_accuracy: 0.6875\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.6979 - val_loss: 0.6439 - val_accuracy: 0.6979\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6927 - val_loss: 0.6425 - val_accuracy: 0.6979\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6944 - val_loss: 0.6411 - val_accuracy: 0.6979\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6979 - val_loss: 0.6398 - val_accuracy: 0.6927\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6927 - val_loss: 0.6385 - val_accuracy: 0.6875\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6944 - val_loss: 0.6372 - val_accuracy: 0.6927\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6927 - val_loss: 0.6360 - val_accuracy: 0.6875\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6962 - val_loss: 0.6348 - val_accuracy: 0.6875\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6979 - val_loss: 0.6336 - val_accuracy: 0.6927\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6944 - val_loss: 0.6324 - val_accuracy: 0.6927\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6944 - val_loss: 0.6313 - val_accuracy: 0.6927\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6927 - val_loss: 0.6302 - val_accuracy: 0.6979\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6944 - val_loss: 0.6292 - val_accuracy: 0.6979\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6927 - val_loss: 0.6281 - val_accuracy: 0.6979\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6962 - val_loss: 0.6271 - val_accuracy: 0.6979\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6962 - val_loss: 0.6261 - val_accuracy: 0.6875\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6962 - val_loss: 0.6251 - val_accuracy: 0.6875\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6944 - val_loss: 0.6242 - val_accuracy: 0.6875\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6979 - val_loss: 0.6232 - val_accuracy: 0.6875\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6979 - val_loss: 0.6222 - val_accuracy: 0.6875\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6944 - val_loss: 0.6213 - val_accuracy: 0.6875\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6944 - val_loss: 0.6204 - val_accuracy: 0.6875\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6944 - val_loss: 0.6194 - val_accuracy: 0.6875\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6944 - val_loss: 0.6185 - val_accuracy: 0.6875\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6944 - val_loss: 0.6175 - val_accuracy: 0.6875\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6962 - val_loss: 0.6166 - val_accuracy: 0.6875\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6944 - val_loss: 0.6157 - val_accuracy: 0.6875\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6927 - val_loss: 0.6148 - val_accuracy: 0.6875\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6910 - val_loss: 0.6138 - val_accuracy: 0.6927\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6910 - val_loss: 0.6129 - val_accuracy: 0.6927\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6944 - val_loss: 0.6120 - val_accuracy: 0.6927\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6944 - val_loss: 0.6111 - val_accuracy: 0.6927\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6944 - val_loss: 0.6102 - val_accuracy: 0.6927\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6962 - val_loss: 0.6093 - val_accuracy: 0.6927\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.6962 - val_loss: 0.6084 - val_accuracy: 0.6927\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6962 - val_loss: 0.6075 - val_accuracy: 0.6927\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6962 - val_loss: 0.6066 - val_accuracy: 0.6927\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6962 - val_loss: 0.6057 - val_accuracy: 0.6927\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6962 - val_loss: 0.6048 - val_accuracy: 0.6927\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6962 - val_loss: 0.6040 - val_accuracy: 0.6927\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6979 - val_loss: 0.6031 - val_accuracy: 0.6927\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6979 - val_loss: 0.6022 - val_accuracy: 0.6927\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6997 - val_loss: 0.6013 - val_accuracy: 0.6927\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7014 - val_loss: 0.6004 - val_accuracy: 0.6927\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6997 - val_loss: 0.5995 - val_accuracy: 0.6927\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7014 - val_loss: 0.5987 - val_accuracy: 0.6927\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7014 - val_loss: 0.5978 - val_accuracy: 0.6927\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7031 - val_loss: 0.5969 - val_accuracy: 0.6927\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7031 - val_loss: 0.5960 - val_accuracy: 0.6927\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7031 - val_loss: 0.5952 - val_accuracy: 0.6927\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7031 - val_loss: 0.5943 - val_accuracy: 0.6927\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7031 - val_loss: 0.5935 - val_accuracy: 0.6927\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7066 - val_loss: 0.5926 - val_accuracy: 0.6927\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7049 - val_loss: 0.5918 - val_accuracy: 0.6927\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7049 - val_loss: 0.5909 - val_accuracy: 0.6927\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7066 - val_loss: 0.5901 - val_accuracy: 0.6927\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7066 - val_loss: 0.5892 - val_accuracy: 0.6927\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7049 - val_loss: 0.5884 - val_accuracy: 0.6927\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7066 - val_loss: 0.5875 - val_accuracy: 0.6927\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7083 - val_loss: 0.5867 - val_accuracy: 0.6979\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7083 - val_loss: 0.5858 - val_accuracy: 0.6979\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7083 - val_loss: 0.5850 - val_accuracy: 0.6979\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7101 - val_loss: 0.5842 - val_accuracy: 0.7031\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7101 - val_loss: 0.5833 - val_accuracy: 0.7031\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7118 - val_loss: 0.5825 - val_accuracy: 0.7031\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7118 - val_loss: 0.5817 - val_accuracy: 0.7031\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7118 - val_loss: 0.5809 - val_accuracy: 0.7031\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7135 - val_loss: 0.5801 - val_accuracy: 0.7031\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7135 - val_loss: 0.5793 - val_accuracy: 0.7031\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7135 - val_loss: 0.5785 - val_accuracy: 0.7031\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7135 - val_loss: 0.5777 - val_accuracy: 0.7031\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7135 - val_loss: 0.5769 - val_accuracy: 0.7083\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7153 - val_loss: 0.5761 - val_accuracy: 0.7083\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7153 - val_loss: 0.5753 - val_accuracy: 0.7083\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7153 - val_loss: 0.5745 - val_accuracy: 0.7083\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7153 - val_loss: 0.5736 - val_accuracy: 0.7083\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7153 - val_loss: 0.5728 - val_accuracy: 0.7083\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7170 - val_loss: 0.5720 - val_accuracy: 0.7083\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7170 - val_loss: 0.5712 - val_accuracy: 0.7083\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7153 - val_loss: 0.5704 - val_accuracy: 0.7083\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7153 - val_loss: 0.5696 - val_accuracy: 0.7135\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7153 - val_loss: 0.5688 - val_accuracy: 0.7135\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7153 - val_loss: 0.5680 - val_accuracy: 0.7188\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7170 - val_loss: 0.5671 - val_accuracy: 0.7188\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7170 - val_loss: 0.5663 - val_accuracy: 0.7188\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7205 - val_loss: 0.5655 - val_accuracy: 0.7188\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7205 - val_loss: 0.5646 - val_accuracy: 0.7188\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7205 - val_loss: 0.5638 - val_accuracy: 0.7240\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7222 - val_loss: 0.5630 - val_accuracy: 0.7240\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7222 - val_loss: 0.5621 - val_accuracy: 0.7240\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7205 - val_loss: 0.5613 - val_accuracy: 0.7240\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7222 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7222 - val_loss: 0.5596 - val_accuracy: 0.7240\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7205 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7205 - val_loss: 0.5580 - val_accuracy: 0.7292\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7205 - val_loss: 0.5572 - val_accuracy: 0.7292\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7205 - val_loss: 0.5564 - val_accuracy: 0.7292\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7205 - val_loss: 0.5556 - val_accuracy: 0.7292\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7205 - val_loss: 0.5548 - val_accuracy: 0.7292\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7222 - val_loss: 0.5541 - val_accuracy: 0.7292\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7222 - val_loss: 0.5533 - val_accuracy: 0.7292\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7222 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7205 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7205 - val_loss: 0.5511 - val_accuracy: 0.7292\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7205 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7205 - val_loss: 0.5497 - val_accuracy: 0.7344\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7205 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7205 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7222 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7222 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7240 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7257 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7240 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7240 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7257 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7257 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7257 - val_loss: 0.5420 - val_accuracy: 0.7344\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7257 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7240 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7240 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7240 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7257 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7257 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7240 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7240 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7222 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7274 - val_loss: 0.5356 - val_accuracy: 0.7240\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7257 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7257 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7257 - val_loss: 0.5338 - val_accuracy: 0.7240\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7274 - val_loss: 0.5332 - val_accuracy: 0.7240\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7292 - val_loss: 0.5327 - val_accuracy: 0.7240\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7274 - val_loss: 0.5321 - val_accuracy: 0.7240\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7292 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7292 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7309 - val_loss: 0.5304 - val_accuracy: 0.7240\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7309 - val_loss: 0.5298 - val_accuracy: 0.7240\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7344 - val_loss: 0.5292 - val_accuracy: 0.7240\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7344 - val_loss: 0.5287 - val_accuracy: 0.7240\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7344 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7361 - val_loss: 0.5276 - val_accuracy: 0.7240\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7361 - val_loss: 0.5271 - val_accuracy: 0.7240\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7361 - val_loss: 0.5266 - val_accuracy: 0.7292\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7361 - val_loss: 0.5261 - val_accuracy: 0.7292\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7361 - val_loss: 0.5256 - val_accuracy: 0.7292\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7361 - val_loss: 0.5251 - val_accuracy: 0.7292\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7361 - val_loss: 0.5246 - val_accuracy: 0.7292\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7396 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7396 - val_loss: 0.5236 - val_accuracy: 0.7292\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7396 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7413 - val_loss: 0.5227 - val_accuracy: 0.7292\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7413 - val_loss: 0.5222 - val_accuracy: 0.7292\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7431 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7431 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7448 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7465 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7483 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7483 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7483 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7517 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7517 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7535 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7535 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7517 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7535 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7535 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7517 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7517 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7517 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7517 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7517 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7517 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7517 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7517 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7535 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7535 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7535 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7535 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7535 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7535 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7535 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7535 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7535 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7535 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7535 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7535 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7535 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7535 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7552 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7552 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7552 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7552 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7552 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7552 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7552 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7552 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7569 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7587 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7587 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7587 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7604 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7622 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7622 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7604 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7622 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7622 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7622 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7622 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7622 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7639 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7639 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7639 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7639 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7639 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7639 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7639 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7639 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7639 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7639 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7639 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7622 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7639 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7639 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7639 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7639 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7639 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7639 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7639 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7639 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7656 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7639 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7674 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7674 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7674 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7674 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7691 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7691 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7708 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7726 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7726 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7726 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7726 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7604\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7604\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7743 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7656\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7795 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7795 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7795 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7812 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7812 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7812 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7830 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7830 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7830 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7830 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7830 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7830 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7830 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7830 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7847 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7847 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7847 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7847 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7847 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7847 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7847 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7500\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7830 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7847 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7830 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7830 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7830 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4892 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7448\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7778 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7778 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7778 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7778 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7830 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7830 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7917 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7899 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7899 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7917 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7708\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7899 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7865 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7865 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7865 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7865 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7899 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7882 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.4938 - val_accuracy: 0.7552\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7552\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7552\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7552\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.4950 - val_accuracy: 0.7552\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.4952 - val_accuracy: 0.7552\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.4953 - val_accuracy: 0.7552\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7448\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7448\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.4957 - val_accuracy: 0.7448\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7448\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.4959 - val_accuracy: 0.7448\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7917 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7917 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7917 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.745\n",
      "roc-auc is 0.823\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUZfr/8fdN6EVAKdKbIFhRWNviggVdFdfyte6uHVl1dXddIFTFQse2v9UFUdG1K8gisrjogsGKBQsIgoTeIXSSkJDk+f0xgxtiyiSZmWfK53VducjMeTLzycPJ3HOfc+Ycc84hIiIisaOK7wAiIiJyOBVnERGRGKPiLCIiEmNUnEVERGKMirOIiEiMUXEWERGJMSrOkrDMrJaZvWNme8xsqu88Ehoze8HMRga/P9vMlof4czeb2ceRTeeXmbU1M2dmVUtY/oCZvRztXBJ+Ks4JwszWmFm2me03sy3BF7i6RcacZWbzzGxfsGC9Y2bHFRlzhJk9YWbrgo+VHrzdqITnNTP7k5l9b2aZZrbBzKaa2YmR/H1DdBXQFDjKOXd1ZR/MzHoFXxifKnL/x2Z2c/D7m4NjBhYZs8HMepXwuJ3M7G0z225mO81sjpkdW9m8oSiy3mw1s+cPrTdmlmZmfYPfH/rdpxf5+ZOD96cVud/MbJWZLa1MPufcR865iM9FMhR2iS8qzonlUudcXaArcAow5NACMzsTeA94G2gOtAO+Az4xs/bBMdWBucDxwK+BI4CzgB3AaSU859+APwN/Ao4EOgEzgEvKG76kbqAS2gA/OufywpglE7jRzNqW8uM7gUFmdkSIT9cAmAkcS+DNxBcE/p+i5dB6cyrwC2B4CeO2A2eZ2VGF7rsJ+LGYsb8CmgDtzewX4QybyCLwNyBxSsU5ATnntgBzCBTpQ8YDLzrn/uac2+ec2+mcGw4sAB4IjrkRaA1c4Zxb6pwrcM5tc8497JybXfR5zKwj8EfgeufcPOdcjnMuyzn3inNubHDMT91X8PZhHUqw6/qjma0AVpjZJDN7pMjzvG1mfw1+39zM3gp2mavN7E/FzYGZPQjcD1wb7ApvM7MqZjbczNaa2TYze9HM6gfHH9pceJuZrQPmlTC9u4EXgBElLAf4AfgMuLeUMT9xzn3hnHsu+H9yEHgcOLZIESz8u9UPZt8e/F2Gm1mV4LKbg538I2a2KzhHF4WYYyPwLnBCCUNyCbzxui74XCnANcArxYy9icAbjNnB70tkZqeY2dfBLTpvADULLetlZhsK3R5sZiuDY5ea2RU/fzj7e3DL0DIzO6/Qgvpm9pyZbTazjWY20sxSzKwLMAk4M7iu7A6OrxGcx3XBrQqTzKxWcFkjM5tlZruDWzs+OvR/UMzv5yywdWmVmWWY2YQi/1+fmNnjZrYTeKC09bSQW81sU/B36V/K3J5hZp8Gc35nhbbeBP82RwaX77fAlrSjzOwVM9trZl+W8SZUIkjFOQGZWUvgIiA9eLs2gQ64uP2ubwK9g9+fD/zHObc/xKc6D9jgnPuicom5HDgdOA54lUBBNQAzawhcALwefEF7h0DH3yL4/H8xswuLPqBzbgQwGnjDOVfXOfcccHPw6xygPVAXeLLIj/YEugA/e8xCRgH/Z6Vver4PuNfMjixlTEl+BWxxzu0oYfnfgfoEfoeeBN5U3VJo+enAcqARgTdlzx2az9KYWSvgYuCbUoa9GHw+CMzREmBTkcepTWCXwivBr+sssFWmuOesTqDgv0Rgy8tU4P9Kef6VwNkEfv8HgZfNrFmh5acDqwj87iOA6YX+D/4J5AHHENiydAHQ1zn3A3AH8FlwXWkQHD+OwJagrsGfaUHgDR9Af2AD0JjA1o6hQGnnQr4C6E5g68RlwK3FZG5CYN26mbLX03OAjsHfYbCZnV/0Cc2sBfBvYCSBuR0AvGVmjQsNuw64Ifi7dSDwpvL54PgfKP1NqESQinNimWFm+4D1wDb+94d1JIH/683F/MxmAi9kAEeVMKYk5R1fkjHBrjEb+IjAi9zZwWVXEXjR3ERgk2tj59xDzrlc59wq4BmCnVwIfgc85pxbFXwDMoRA4Si8KfEB51xmMEuxglsmJgEPlTLmWwK7EQaFmA346Y3VU8BfS1ieAlwLDAluAVkDPErgBfaQtc65Z5xz+QQKUjMCBaQkM4Ld4sfAfAJvaorlnPsUODL4xuRGAsW6qCuBHAK//yygKiXv5jgDqAY84Zw76JybBnxZyvNPdc5tCm7VeQNYweG7XLYVeqw3CLxJucTMmhJ4w/qX4P/vNgJbKIpdd4JvZm4H7g2um/sIzMuh8QcJzGub4HN95Eq/UMG44OOsA54Ari+0bJNz7u/OubzgehfKevpg8PdYTKCYFn68Q34PzHbOzQ7O1/vAVwTegB3yvHNupXNuD4GtJiudc/8N7gqaSuBNjHig4pxYLnfO1QN6AZ35X9HdBRQQeDEpqhmQEfx+RwljSlLe8SVZf+ib4Avc6/zvxea3/G+zaRugeXAT3e5gQRlK6YWnsObA2kK31xIoHIV/fj2hGQdcaGYnlzLmfuBOMzu68J3BTYiHvloXur8xgYL2D+fcayU8ZiOgejG/R4tCt7cc+sY5lxX89rCDA4u43DnXwDnXxjl3V2lvTIJeAu4m0L39q5jlNwFvBotNDjCdkjdtNwc2Filsa0sYi5ndaGbfFvr/P4H/reeU8FjNCaw71YDNhX72aQLdanEaA7WBhYXG/yd4P8AEAlum3gturh5cUuagwuvVoUzFLYPyr6dFH++QNsDVRf5eenD43+zWQt9nF3O7tPVGIkjFOQE55+YT2C/6SPB2JoHNVcUdsXwNgYPAAP5LoODUCfGp5gItzax7KWMyCbzIHXJ0MWOKdhyvAVeZWRsCm/zeCt6/HlgdLCSHvuo55y4mNJsIvGAd0prAZs7CL0ghXaYtuMn5CeDhUsYsI1CYhha5v26hr3Xw0+b794CZzrlRpTx1BoGurejvsTGU3GHyEnAXga4sq/CCYOd/LvB7C3xqYAuBrR8XW/FH/G8GWhTZ7N66mHEE14dnCLwxOCq4+fl7oPDPFvdYmwisOzlAo0LrzhHOueOD44r+v2cQKE7HFxpfP3jgHMGtFv2dc+2BS4G/Ft6/XYxWxWQ6pOhzh7KelvZ4h6wHXiry91Ln0PEgEttUnBPXE0BvMzt0UNhg4KbggSn1zKyhBT5LeiaBfXcQeNFdT2C/VOfggSlHmdlQM/tZAXTOrQD+AbxmgQN3qptZTTO7rlAn8S1wpZnVNrNjgNvKCu6c+4bAkcHPAnOcc7uDi74A9prZIAt8hjnFzE6w0I8Gfo3AfuB2Fvi40KF90uU+mjvoMQL78ruUMuZBAvuDG5Q0wAJHdc8BPnHOldqBBTdVvwmMCv4/tiGwCTxqn211zq0msK97WDGLbyBw9PaxBPbVdiWw33YDxW96/YxA4fmTmVU1sysp+ZMBdQgUsu0AZnYLPz94rUnwsaqZ2dUE/m9mO+c2E3jz86gFPi5Yxcw6mFnP4M9tJfBGs3rwdywg8EbgcTNrEny+FoeObzCzPmZ2TPCNwF4gP/hVkoHBv7lWBD7d8EYpY0NZT+8L/k0dT2D9Ku7xXgYuNbMLg38rNYN/py1LeW6JESrOCco5t53A/sD7grc/JnAAz5UEupW1BPYn9QgWWYKbIM8HlgHvE3jR+YLAZsPPS3iqPxE4WOUpAkcyryRw8Ms7weWPEzjKdyuB/Z/FHdlbnNeCWV4t9DvlE+hSugKrCXQ3zxI4OCgUUwi8Afkw+PMHgHtC/Nmfcc7tJXDAVYkHfQUL2UsECktJriCwP/2WkjZ5F3EPgS0SqwjsJ36VwO8WNc65j4PHARR1E4HN8lsKfxHYR/+zTdvOuVwC6+TNBHa/XEtga0Nxz7mUwP71zwisTycCnxQZ9jmBA6UyCBxcdZX734F1NxLYJbA0+FzT+N8m3nkEDm7bYmaHdvMMIrDpeoGZ7SWwZenQQYAdg7f3B/P8wzmXVlzuoLeBhQTerP4beK6UsaGsp/OD2eYCjzjn3iv6IM659QQOPhtK4A3NemAget2PC1b6MQwiIlIZZuaAjs65dN9ZJH7oHZSIiEiMUXEWERGJMdqsLSIiEmPUOYuIiMQYFWcREZEYU+YVUMxsCtAH2Oac+9kJ8YOf8/sbgVPCZQE3O+e+LutxGzVq5Nq2bXvYfZmZmdSpE+r5L6Q8NLeRpfmNHM1tZGl+I6e4uV24cGGGc65xCT/yk1AuT/YCgc+xFncOXQicr7Zj8Ot0YGLw31K1bduWr7766rD70tLS6NWrVwiRpLw0t5Gl+Y0czW1kaX4jp7i5NbMST09bWJmbtZ1zHxK4Pm1JLiNwKULnnFsANChylRgREREph3Bc2LsFh5+EfUPwvnBcrUhERCLsxRdfZOHChb5jJJxNmzZVeKtEOIpzcdeJLfbzWWbWD+gH0LRpU9LS0g5bvn///p/dJ+GhuY0szW/kaG4ja//+/fzpT38iKyuLGjVq+I6TMHJzc6lRo0aF191wFOcNHH6FlJYUf4UUnHOTgckA3bt3d0XfUWjfR+RobiNL8xs5mtvISktLo2rVqvTr148nn3zSd5yEsGzZMpxzbN26tcLrbjg+SjUTuNECzgD2BK8AIyIiklQmTJjAli1b6NKltIvVlS2Uj1K9BvQCGpnZBmAEgYuW45ybBMwm8DGqdAIfpbqlUolERETijHOOuXPn0rdvXxo2bFjpxyuzODvnirsGa+HlDvhjpZOIiIjEqb/97W+ceeaZYSnMEJ59ziIiIkmpoKCAl156iXvuuYeUlJSwPa5O3ykiIlJBL774Il27dg1rYQZ1ziIiIuWWl5fHo48+SmpqKoGzWIeXOmcREZFy+s9//sPll18ekcIMKs4iIiIhy83NZeDAgfTu3Ztjjz02Ys+j4iwiIhKC3Nxcvv76a/74xz9G/Gxq2ucsIpKAcnJyWLx4MYFPu5Zs2bJlHDx4MEqp4ld2djapqak8+OCDHHnkkRF/PhVnEZEEdP/99zN+/PiQx+uaziXLzMxk5cqVDBkyJCqFGVScRUQS0p49e6hfvz6vvPJKqeMWLVrEySefTI8ePaKULL7s27ePwYMHM2LECJo0aRK151VxFhFJUDVr1uSSSy4pdUydOnV0YZES7N69mzVr1vDggw/SqFGjqD63DggTEREpIjMzk6FDh9K6deuoF2ZQ5ywiInKYjIwMli9fziOPPELt2rW9ZFBxFpGEdeDAAd8RvMnLy/MdIS7l5+czcuRIHn74YW+FGVScRSRBPfDAAzz44IO+Y3jVokUL3xHiyqZNm/j88895/PHHI3bmr1CpOItIQkpPT+fII49k4MCBvqN4c8opp/iOEFeef/55/vrXv3ovzKDiLCIJrGHDhgwePNh3DIlxa9as4b333mPYsGG+o/xER2uLiEjScs4xb948br75Zt9RDqPOWUREktKyZcuYPn06Q4cO9R3lZ9Q5i4hI0snMzGT16tWkpqb6jlIsdc4iEnUzZsxg8ODBFBQUlDk2OzubWrVqlfs5Nm/eTNOmTSsSTxLcd999x9SpUxk5cqTvKCVScRaRqPv4449JT0/nmmuuKXPs1q1bK1xkdVpKKWrNmjU453jooYd8RymVirOIeFGzZk1effXVMselpaWpyEpYfPHFF8yePZsRI0bExMelSqN9ziIikvC+/PJLjj766LgozKDiLCIiCe6rr75i3rx5tGrVKi4KM6g4i4hIAvvvf/9L8+bNGTRoUNwUZtA+Z5GkkJ+fzz333MO2bdt8RwFg0aJFviNIEli+fDlLly7l/PPP9x2l3FScRZLAunXrmDhxIs2bN6dhw4a+41C9enWuuuoq3zEkgb399tt06dKFP/3pT76jVIiKs0gSGT16NDfddJPvGCIRtW3bNrZv385ll13mO0qFqTiLiEjCeP3112nbti19+/b1HaVSdECYiIgkhH379pGSksIZZ5zhO0qlqXMWEZG4N2XKFFq0aMHVV1/tO0pYqDiLxLH58+czf/78Msft2rUrCmlE/MjIyKBdu3acc845vqOEjYqzSBwbMGAAX331VUhjq1evTrt27SKcSCS6nnrqKdq2bcsll1ziO0pYqTiLxLH8/Hz69OnD22+/HdL4KlV0mIkkju+//57zzz+fY4891neUsNNfqkicMzOqVKkS0pdIonj88cfZsmVLQhZmUOcsIiJxxDnHe++9x6233kr9+vV9x4kYvZUWEZG48Y9//IO6desmdGEGdc4iIhIHnHM8//zz3HnnnUmxiybxf0MREYl7r732Gl27dk2KwgzqnEVEJIbl5+czfvx4UlNTSUlJ8R0napLjLYiIiMQd5xxz587lsssuS6rCDCrOIiISgw4ePEhqaiq//OUvOe6443zHiTpt1hYRkZiSm5vL4sWLueOOO6hTp47vOF6ocxYRkZhx4MABBgwYQKtWrejQoYPvON6ocxYRkZiQlZXFypUrSU1NpUmTJr7jeKXOWUREvMvMzCQ1NZXGjRvTsmVL33G8U+csIiJe7d27l1WrVjFixAgaN27sO05MUOcsIiLeHDhwgCFDhtCqVSsV5kLUOYuIiBc7d+5k8eLFPPLII9SqVct3nJiizllERKKuoKCAUaNG0bVrVxXmYqhzFomC3bt3c/LJJ5ORkRHWx83OzqZ169ZhfUyRSNuyZQsffvghjzzyCGbmO05MUnEWiYKtW7eybt06LrnkErp06RLWx77yyivD+ngikfbPf/6Tu+++W4W5FCrOIlH0u9/9juuvv953DBEv1q1bx8yZMxk0aJDvKDFP+5xFRCTiCgoK+OCDD7j99tt9R4kL6pxFRCSiVqxYwauvvsqIESN8R4kb6pxFRCRi9u3bx5o1axg2bJjvKHFFnbNIOSxdupS77rqLnJycw+7fu3cvRxxxRIk/l52dHeloIjHn+++/5+WXX2bMmDE6+KucVJxFymHBggXMnz+fs88++7DPZubl5ZVanI844gh+85vfcNZZZ0Ujpoh3q1atoqCggNGjR6swV4CKs0gFvPzyy4d9vjgtLY1evXr5CyQSQxYuXMiMGTN48MEHqVJFe08rQrMmIiJh89VXX9GoUSMeeughFeZK0MyJiEhYfPfdd8yZM4fWrVtrU3YlqTiLiEilffDBBzRo0IChQ4eqMIeB9jlLUvryyy957rnncM6V6+eWLVsWoUQi8Wv16tV88803nHPOOb6jJAwVZ0k6+/fv5/LLL2f37t2lHmFdkq5du+q6syJB//73v2ndujV//etffUdJKCrOknTGjRvHpk2b+OSTT/TRJpFK2LVrFxs2bOCSSy7xHSXhqDhLUlmzZg2PPPII119/vQqzSCVMnTqVJk2a8Ic//MF3lISkA8IkqaSmpmJmjBs3zncUkbiVlZUFQM+ePT0nSVzqnCVpfPjhh0ydOpUHHniAVq1a+Y4jEpdefPFFGjZsyNVXX+07SkJTcZaYMGPGDDZu3BjR55g0aRKtWrVi4MCBEX0ekUS1fft22rRpo445ClScxbtdu3ZxxRVXRPx5qlatyhtvvEHt2rUj/lwiiebpp5/m6KOP5rLLLvMdJSmoOIt3eXl5AIwZM4bbbrstYs9To0aNCn10SiTZLVq0iPPOO49jjjnGd5SkoeIsMaNevXr6/LBIjHnyySfp2LEjF154oe8oSUXFWUREfsY5x7vvvstNN91EvXr1fMdJOvoolYiI/Myzzz5LvXr1VJg9UecsIiI/cc7x7LPPctttt+mSjx5p5kVE5CfTp0+na9euKsyeqXMWEREKCgoYPXo0gwYNolq1ar7jJL2Q3hqZ2a/NbLmZpZvZ4GKW1zezd8zsOzNbYma3hD+qiIhEgnOODz/8kMsuu0yFOUaUWZzNLAV4CrgIOA643syOKzLsj8BS59zJQC/gUTOrHuasIiISZvn5+aSmpnLKKadw4okn+o4jQaF0zqcB6c65Vc65XOB1oOgpYhxQz8wMqAvsBPLCmlRERMIqNzeX1atX069fP+rXr+87jhQSyj7nFsD6Qrc3AKcXGfMkMBPYBNQDrnXOFRR9IDPrB/QDaNq0KWlpaYct379//8/uk/CI5bndvXs3AD/++GPMZixLLM9vvNPcRkZubi5PP/00v/nNb9i4cWPEz22fjCqz7oZSnK2Y+1yR2xcC3wLnAh2A983sI+fc3sN+yLnJwGSA7t27u169eh32IGlpaRS9T8Ijlud2+/btAHTq1ClmM5Ylluc33mluw+/AgQOkp6fz+OOPs2rVKs1vhFRm3Q1ls/YGoPD19VoS6JALuwWY7gLSgdVA5wolEhGRiMnKymLgwIE0bNiQ1q1b+44jJQilOH8JdDSzdsGDvK4jsAm7sHXAeQBm1hQ4FlgVzqAiIlI5+/fvZ9myZdx///20aNHCdxwpRZnF2TmXB9wNzAF+AN50zi0xszvM7I7gsIeBs8xsMTAXGOScy4hUaBERKZ+DBw+SmppKy5YtdYGZOBDSSUicc7OB2UXum1To+03ABeGNJiIi4bBr1y6++uorHn/8cWrUqOE7joRA52cTEUlgzjnGjBnDL37xCxXmOKLTd4oXkyZNYvTo0UDgJAgiEn7btm3j/fffZ9y4cQROQyHxQsVZvPj444/ZtWsXV199NQDVqlWjT58+nlOJJJaXXnqJP/zhDyrMcUjFWbxp2rQpU6ZM8R1DJOFs3LiRN998k/79+/uOIhWkfc4iIgmkoKCA+fPnc+edd/qOIpWgzllEJEGsWrWKKVOmMHLkSN9RpJLUOYuIJIA9e/awdu1aRowY4TuKhIGKs4hInPvhhx8YOXIkvXr10vWYE4SKs4hIHFu5ciX5+fmMHTtWR2UnEBVnEZE4tWjRIp577jmOO+44UlJSfMeRMFJxFhGJQwsXLqRevXqMHDmSKlX0Up5o9D8qIhJnli5dyuzZs2nbtq0Kc4LS/6qISBz58MMPqV69OsOHD9c+5gSm4iwiEic2bdrE559/TocOHVSYE5xOQiIiEgfmzJlDo0aNGDhwoO8oEgXqnEVEYtz+/ftZvXo13bp18x1FokSds4hIDPvXv/5F3bp1ueOOO3xHkShS5ywiEqOys7PJz8+nd+/evqNIlKlzFhGJQa+88gq1atXiqquu8h1FPFBxlrA5ePAg7777LllZWWWOXbNmTeQDicSprVu30qZNG3r06OE7inii4ixhM3fuXC677LKQx5922mkRTCMSn5599lkaNGigjjnJqThL2Bw4cACA6dOn06VLlzLHt2zZMtKRROLKN998w3nnnUe7du18RxHPVJwl7Nq1a0fnzp19xxCJK08//TQtW7bklFNO8R1FYoCKs4iIZzNnzuT3v/89derU8R1FYoQ+SiUi4tELL7xA3bp1VZjlMOqcpUw7duxg69atZY5bv359FNKIJAbnHJMnT6Zv3766FrP8jIqzlKlz585kZGSEPL5WrVoRTCOSGGbNmsVJJ52kwizFUnGWMu3cuZMrr7ySa6+9tsyxDRs2pFOnTlFIJRKfCgoKGD16NAMGDKBmzZq+40iMUnGWkBx33HFcc801vmOIxDXnHAsWLKBPnz4qzFIqHRAmIhIFeXl5DBo0iE6dOtG1a1ffcSTGqXMWEYmwgwcPsmzZMm699VYaNWrkO47EAXXOIiIRlJubS2pqKvXr19fJeSRk6pxFRCIkJyeH9PR0/vznP9O6dWvfcSSOqHMWEYmAAwcOMHDgQOrVq0fbtm19x5E4o85ZRCTMMjMz+eGHH7jvvvto3Lix7zgSh9Q5i4iEUX5+PoMHD6ZVq1YqzFJh6pxFRMJkz549fPrppzz66KNUr17ddxyJY+qcRUTCZMKECZx++ukqzFJp6pxFRCopIyODWbNmMXLkSN9RJEGocxYRqaRXX32VK6+80ncMSSDqnEVEKmjz5s289NJLpKam+o4iCUads4hIBeTn5/PRRx9x9913+44iCUjFWUSknNasWcPQoUO55pprqF27tu84koBUnEVEymHXrl2sW7eOhx9+2HcUSWDa55zApk2bxjvvvAPAli1beP755yv0OAUFBeGMJRK3li9fzuTJkxk/fjwpKSm+40gCU3FOYI8++ijffvstRx99NAcOHODHH3+s0ON06NCBM844I8zpROJLeno6eXl5jBs3ToVZIk7FOcH96le/Ys6cOaSlpdGrVy/fcUTi0pIlS3j55ZcZOXKkCrNEhfY5i4iU4ptvvqFmzZqMGjVKhVmiRsVZRKQE6enpzJgxg/bt21Olil4uJXq0tomIFOOTTz7h4MGDPPDAA5iZ7ziSZFScRUSK2L59Ox999BGdO3dWYRYvdECYiEgh//3vf6lduzaDBw/2HUWSmDpnEZGg7OxsVqxYwVlnneU7iiQ5dc4iIsDMmTOpUqUKd955p+8oIuqcRUSys7PJzc2lT58+vqOIAOqcRSTJvf766wBcd911npOI/I+Ks4gkrc2bN9OmTRvOPPNM31FEDqPiLCJJ6fnnn6dWrVrqmCUmqTiLSNL56quvOO+882jdurXvKCLF0gFhIpJUpkyZwsaNG1WYJaapcxaRpDFjxgyuu+46ateu7TuKSKnUOYtIUnj99depU6eOCrPEBXXOIpLQnHM8/fTT9O3bl6pV9ZIn8UGds4gktPfee48TTjhBhVniioqziCQk5xyjRo2iR48e9OjRw3cckXLRW0kRSTgFBQV8/fXX/PrXv6ZOnTq+44iUmzpnEUko+fn5DB06lBYtWtCtWzffcUQqRJ2ziCSMvLw8VqxYwQ033ECzZs18xxGpMHXOIpIQDh48yKBBg6hRowbHH3+87zgilaLOWUTiXm5uLitWrOCPf/wj7du39x1HpNLUOYtIXMvNzWXgwIHUqVNHhVkShjpnEYlb2dnZLFq0iPvuu49GjRr5jiMSNuqcRSQuOecYMmQIrVu3VmGWhKPOWUTizr59+/jggw+YMGEC1apV8x1HJOzUOYtI3Hn00Uc566yzVJglYalzjjPffvstgwcPJi8vr8yxS5cu5YwzzohCKpHo2LlzJ2+99RYPPPCA7ygiERVS52xmvzaz5WaWbmaDSxjTy8y+NbMlZjY/vDHlkP/+95dxQvAAACAASURBVL/MmTOHzMxMDhw4UOrXiSeeyNVXX+07skjYvPHGG1xzzTW+Y4hEXJmds5mlAE8BvYENwJdmNtM5t7TQmAbAP4BfO+fWmVmTSAWWgPfff5+6dev6jiESFVu3buWZZ55h+PDhvqOIREUonfNpQLpzbpVzLhd4HbisyJjfAtOdc+sAnHPbwhtTRJJVfn4+n3zyCffee6/vKCJRE0pxbgGsL3R7Q/C+wjoBDc0szcwWmtmN4QooIslr/fr1PP3001xxxRW6upQklVAOCLNi7nPFPE434DygFvCZmS1wzv142AOZ9QP6ATRt2pS0tLTDHmT//v0/u08Ot3LlSgA++ugjatWqFfLPaW4jS/Mbfnv27GHDhg1cd911zJ+vw1giRetu5FRmbkMpzhuAVoVutwQ2FTMmwzmXCWSa2YfAycBhxdk5NxmYDNC9e3fXq1evwx4kLS2NovclA+cc48aNY9u2svcGLFmyBICzzz67XPuck3Vuo0XzG17p6enMmDGDRx55hI8//lhzG0FadyOnMnMbSnH+EuhoZu2AjcB1BPYxF/Y28KSZVQWqA6cDj1coURJau3YtQ4YMoUaNGlSvXr3M8SeddBI1a9aMQjKR6Fu5ciU5OTlMmDCBqlX1aU9JTmWu+c65PDO7G5gDpABTnHNLzOyO4PJJzrkfzOw/wCKgAHjWOfd9JIMnEucCewmefvppbrrpJs9pRPxZvnw5zz33HKNHj1ZhlqQW0trvnJsNzC5y36QitycAE8IXTUSSyXfffUetWrUYM2YMKSkpvuOIeKXTd4qId+vWrWPq1Kkcc8wxKswi6PSdIuLZ559/Tq1atXj44YcxK+7DISLJR8XZkzVr1vx0iP327dv9hhHxZPfu3cybN4/BgwerMIsUouLsyaBBg3jzzTcPu69JE531VJLHoTenQ4YM8RtEJAapOHuSk5NDly5dmD07cJxdjRo1aNasmedUItGRm5vLsmXLuOOOO3xHEYlJKs4eVa9enbZt2/qOIRJVs2fP5sCBAyrMIqXQ0doiEjXZ2dnk5ORw5ZVX+o4iEtPUOYtIVEybNo3s7GxuuOEG31FEYp6KcxStWLGCffv2AYGjVEWSxYYNG2jdujWnnXaa7ygicUHFOUoWLVrEySeffNh9Z555pqc0ItHz8ssvY2b87ne/8x1FJG6oOEfJoU754Ycf5qSTTgL46V+RRPX5559zzjnn0KJF0UvAi0hpVJyj7KyzzuLcc8/1HUMk4l566SXq1KnD6aef7juKSNxRcRaRsHvrrbe46qqrqFWrlu8oInFJH6USkbCaPn06derUUWEWqQR1ziISFs45Jk6cSN++falevbrvOCJxTZ2ziITF/PnzOf7441WYRcJAxVlEKsU5x6hRo+jatSs9e/b0HUckIag4i0iFOedYtGgRvXv3pkGDBr7jiCQMFWcRqZCCggKGDx9Ow4YNdeYvkTDTAWEiUm75+fmsWrWKa6+9ltatW/uOI5Jw1DmLSLnk5eUxePBgnHM6y51IhKhzjqD777+fadOmAZCZmek5jUjlHTx4kB9//JE77riDDh06+I4jkrDUOUfQv//9b3bt2sUJJ5zA6aefzq233kq3bt18xxKpkLy8PFJTU6lZs6YKs0iEqXOOsO7du/Pmm2/6jiFSKQcOHGDhwoXcd999HHnkkb7jiCQ8dc4iUirnHMOGDaNNmzYqzCJRos5ZREq0f/9+3nvvPcaNG0fVqnq5EIkWdc4iUqK//e1v9OjRQ4VZJMr0FxeCoUOHsnLlynL/3KpVq2jevHkEEolE1u7du3n11VcZNmyY7ygiSUnFuQzZ2dmMGTOGRo0a0ahRo3L97NFHH82FF14YoWQikTNt2jSuv/563zFEkpaKc4gGDBjAoEGDfMcQiajt27fz1FNP8cADD/iOIpLUtM9ZRIDACUYWLFhA//79fUcRSXoqziLCxo0bGThwIH369KFevXq+44gkPRVnkSS3fft2Nm7cyJgxYzAz33FEBO1zBgInWZg8eTIZGRk/W3bw4EEPiUSiY/Xq1TzxxBNMmDCB6tWr+44jIkEqzsDKlSu54447SlxepUoVnUtYEs7KlSvJyclRYRaJQdqsTeDatAAvvvgiubm5P/vKycnhqquu8pxSJHxWrlzJxIkT6dSpkwqzSAxS51xI1apVqVatmu8YIhH1/fffk5KSwrhx40hJSfEdR0SKoc5ZJIls3ryZV199lWOPPVaFWSSGqXMWSRJfffUVAKNGjdJR2SIxLmmKc0FBAfPnz2f//v0/W7ZhwwYPiUSiJzMzkzlz5jB06FAVZpE4kDTFecGCBZx77rmljmnQoEGU0ohEz0cffURWVpYuYiESR5KmOGdlZQHwzDPPcMopp/xsec2aNTnuuOOiHUskovLy8li6dCn9+vXzHUVEyiFpivMhnTt3plu3br5jiETcnDlz2LlzJ3/4wx98RxGRctLR2iIJKCsriwMHDuiyjyJxKuk6Z5FEN2PGDHbu3Mmtt97qO4qIVFBCF+ecnBy2bNkCwNatWz2nEYm8tWvX0qpVKy6//HLfUUSkEhK6OF9yySXMnTv3sPtq1KjhKY1IZL322mvk5uZy0003+Y4iIpWU0MV569atnHrqqdx9990AHHHEEToYTBLSJ598Qq9evWjWrJnvKCISBgldnAHatm3LLbfc4juGSMS8/vrrVKlShV/+8pe+o4hImCR8cRZJZNOmTePyyy+nZs2avqOISBjpo1QicWrWrFnUqFFDhVkkAalzFolDEydO5Oabb6ZWrVq+o4hIBKhzFokzn376Kccee6wKs0gCU3EWiRPOOcaMGUPHjh3LvIiLiMQ3FWeROOCcY9myZfTs2ZPGjRv7jiMiEabiLBLjCgoKGDFiBNWqVeOss87yHUdEokDFWSSGFRQUsHr1aq688kqOOeYY33FEJEpUnEViVH5+PkOGDCEnJ4euXbv6jiMiUaSPUonEoLy8PJYvX06/fv3o0KGD7zgiEmXqnEViTEFBAampqVSvXl2FWSRJqXMWiSE5OTl8/vnn3H///TRo0MB3HBHxRJ2zSAwZMWIEbdu2VWEWSXLqnEViQFZWFrNmzWLUqFGkpKT4jiMinqlzFokBTz31FL/61a9UmEUESLDOecuWLYwbN46cnBwANm7cSKdOnTynEinZ3r17ef755xk4cKDvKCISQxKqOL/77rs88cQTHHnkkaSkpFC1alXOOOMM37FEiuWc41//+he///3vfUcRkRiTUMXZOQfAN998Q+vWrT2nESnZjh07ePTRRxk9erTvKCISg7TPWSTKcnJy+OKLLxg8eLDvKCISo1ScRaJo8+bNDBgwgAsuuIAjjjjCdxwRiVEqziJRsm3bNjZu3Mi4ceN0VLaIlErFWSQK1q5dy8iRIznhhBOoXbu27zgiEuMS6oAwkVi0evVqsrKymDBhAjVq1PAdR0TigDpnkQhau3Ytf//73+nUqZMKs4iETJ2zSIT88MMP5OfnM378eKpW1Z+aiIROnbNIBGRkZPDCCy/QpUsXFWYRKTe9aoiE2TfffEN2djZjx47FzHzHEZE4FFLnbGa/NrPlZpZuZiWeOcHMfmFm+WZ2VfgiisSPAwcOMHv2bM444wwVZhGpsDI7ZzNLAZ4CegMbgC/NbKZzbmkx48YBcyIRVCTWffrpp+zYsYNhw4b5jiIicS6Uzvk0IN05t8o5lwu8DlxWzLh7gLeAbWHMJxIX8vPz+f777+nTp4/vKCKSAEIpzi2A9YVubwje9xMzawFcAUwKXzSR+DB37lzef/99+vXrp03ZIhIWoRwQVtyrjSty+wlgkHMuv7QXJzPrB/QDaNq0KWlpaYct379//8/uK49ly5YB8Nlnn7Fq1aoKP04iquzcSvGys7P59ttv6dGjh+Y3QrTuRpbmN3IqM7ehFOcNQKtCt1sCm4qM6Q68HizMjYCLzSzPOTej8CDn3GRgMkD37t1dr169DnuQtLQ0it5XHocK8plnnqlLRhZR2bmVn5s1axabNm1iyJAhmt8I0txGluY3ciozt6EU5y+BjmbWDtgIXAf8tvAA51y7Q9+b2QvArKKFWSSRrFq1ipYtW2ofs4hERJnF2TmXZ2Z3EzgKOwWY4pxbYmZ3BJdrP7MklalTp7J3715uu+0231FEJEGFdBIS59xsYHaR+4otys65mysfSyQ2ffjhh/Ts2ZMmTZr4jiIiCUyn7xQJ0fTp09m0aZMKs4hEnE7fKRKCqVOn0qdPH2rVquU7iogkAXXOImV4//33qVatmgqziESNOmeRUkycOJEbbriBunXr+o4iIklEnbNICRYuXEiHDh1UmEUk6lScRYpwzjF+/HiaNWvGBRdc4DuOiCQhFWeRQpxzrFy5kjPPPJPmzZv7jiMiSUrFWSTIOceDDz7IwYMHOfvss33HEZEkpgPCRICCggLWrl3Lb37zG7p06eI7jogkOXXOkvQKCgoYNmwY+/bt49RTT/UdR0REnbMkt/z8fJYuXcrtt99O+/btfccREQHUOUsSc84xePBgqlWrpsIsIjFFnbMkpdzcXD766COGDx9O/fr1fccRETmMOmdJSg899BDt27dXYRaRmKTOWZJKdnY206dP56GHHqJKFb03FZHYpFcnSSqTJk2iV69eKswiEtPUOUtS2LdvH5MnT6Z///6+o4iIlEntgyQ85xzvvPMON954o+8oIiIhUXGWhLZr1y4GDRrE9ddfT+PGjX3HEREJiYqzJKwDBw6wcOFChg4dipn5jiMiEjIVZ0lIW7dupX///vTs2ZMGDRr4jiMiUi4qzpJwtm3bxsaNGxk/fjzVqlXzHUdEpNxUnCWhbNiwgYcffpguXbpQp04d33FERCpEH6WShLF27Vr279/PhAkTqFmzpu84IiIVps5ZEsKmTZt44okn6NixowqziMQ9dc4S93788Ueys7O1j1lEEoY6Z4lre/bs4dlnn+X4449XYRaRhKHOWeLWokWL2LlzJ+PGjdPnmEUkoahzlrh08OBBZs2axa9+9SsVZhFJOOqcJe588cUXrF+/nqFDh/qOIiISEeqcJa4UFBSwaNEirrzySt9RREQiRp2zxI20tDRWrFjB7bff7juKiEhEqXOWuLB3716ys7Pp27ev7ygiIhGnzlli3rvvvsvKlSu5++67fUcREYkKFWeJaStWrKBly5ZcdNFFvqOIiESNNmtLzJoxYwZpaWmceOKJvqOIiESVOmeJSWlpafTo0YNGjRr5jiIiEnXqnCXmvPPOO2zYsEGFWUSSljpniSlvvPEGl156KbVr1/YdRUTEG3XOEjPmz59P1apVVZhFJOmpc5aYMGnSJK699loaNmzoO4qIiHdxX5zvuusuvvzySwC2b9/uOY1UxOLFi2ndurUKs4hIUNxv1n7llVfIyMigSZMmHH/88dx66620aNHCdywJ0aOPPkrdunW5+OKLfUcREYkZcd85A1x++eU8/vjjvmNIOTjnWLduHd26daNdu3a+44iIxJS475wl/jjnGDVqFLt376ZXr16+44iIxBwVZ4kq5xxr167loosu4uSTT/YdR0QkJqk4S9QUFBRw3333sWvXLrp16+Y7johIzIq7fc4//PADjz/+OPn5+QBkZWV5TiShyM/P5/vvv+e2227TPmYRkTLEXXF+4403eOaZZ2jZsiUAzZs354wzzvCcSkrjnGPYsGHccMMNKswiIiGIu+J8yPr1631HkBAcPHiQDz74gGHDhlGvXj3fcURE4oL2OUtEjR49mvbt26swi4iUQ9x2zhLbDhw4wBtvvMF9991HlSp6DygiUh561ZSImDJlCueee64Ks4hIBahzlrDKzMzkySefZNCgQb6jiIjELbU1EjbOOWbPns3NN9/sO4qISFxTcZaw2L17N/379+f//u//aNq0qe84IiJxTcVZKi07O5vvvvuO4cOHax+ziEgY6JVUKiUjI4MBAwZw+umnc+SRR/qOIyKSEHRAmFTY9u3b2bhxI2PHjqVmzZq+44iIJAx1zlIhmzdv5sEHH6Rjx446wYiISJipc5ZyW79+Pbt372bChAnUqlXLdxwRkYSjzlnKZdu2bTzyyCN07NhRhVlEJELUOUvI0tPT2bNnDxMmTKB69eq+44iIJCx1zhKSzMxMJk+ezEknnaTCLCISYeqcpUxLlixh48aNjBs3DjPzHUdEJOHFReecnZ1NRkYGGRkZZGVl+Y6TVPLz85k5cybnnXeeCrOISJTEfOecm5tLq1at2LFjx0/3Va0a87ETwsKFC1m+fDlDhgzxHUVEJKnEfJXLzs5mx44dXHHFFZx77rkAHHPMMZ5TJb78/HwWL17MTTfd5DuKiEjSifnifMjZZ5/N3Xff7TtGUvj4449ZtGgRd911l+8oIiJJKS72OUv07Nmzh6ysLO68807fUUREklbcdM4See+//z5LlizhL3/5i+8oIiJJTcVZAFi2bBktWrSgd+/evqOIiCQ9bdYWZs2axQcffMBxxx3nO4qIiKDOOel98MEHnHnmmfTp08d3FBERCVLnnMT+85//sHbtWo466ijfUUREpBB1zknqzTff5OKLL6Zu3bq+o4iISBHqnJPQggULAFSYRURiVEjF2cx+bWbLzSzdzAYXs/x3ZrYo+PWpmZ0c/qgSDs888wzt27fnmmuu8R1FRERKUGZxNrMU4CngIuA44HozK3pY72qgp3PuJOBhYHK4g0rl/fjjjxx99NE0adLEdxQRESlFKJ3zaUC6c26Vcy4XeB24rPAA59ynzrldwZsLgJbhjSmVNW3aNJxzXHrppb6jiIhIGUI5IKwFsL7Q7Q3A6aWMvw14t7gFZtYP6AfQtGlT0tLSDlu+f//+Yu8DSE9P/9kyKZtzjh07dtCsWTM2b97M5s2bfUdKSMWtuxIemtvI0vxGTmXmNpTiXNxFfF2xA83OIVCcexS33Dk3meAm7+7du7tevXodtjwtLY2i9+3ZswcIXImq6DIpnXOOsWPH0rt3bxo1aqT5i6Di1l0JD81tZGl+I6cycxvKZu0NQKtCt1sCm4oOMrOTgGeBy5xzO4oul+hyzrFu3Tp69+5N9+7dfccREZFyCKU4fwl0NLN2ZlYduA6YWXiAmbUGpgM3OOd+DH9MKQ/nHCNGjGDbtm0qzCIicajMzdrOuTwzuxuYA6QAU5xzS8zsjuDyScD9wFHAP8wMIM85p6rgQUFBAd999x233XYbbdq08R1HREQqIKQzhDnnZgOzi9w3qdD3fYG+4Y0mFTFixAiuueYaFWYRkTim03cmiLy8PN577z0GDx5MnTp1fMcREZFK0Ok7E8T48eM55phjVJhFRBKAOuc4l5OTw0svvcSQIUMI7u8XEZE4p845zv3zn/+kd+/eKswiIglEnXOcysrK4rHHHmPYsGEqzCIiCUadcxxyzvHee+9x2223qTCLiCQgFec4s3fvXu69914uvfRSmjVr5juOiIhEgIpzHMnMzGTx4sUMHz6clJQU33FERCRCVJzjxM6dOxk4cCBdu3alUaNGvuOIiEgE6YCwOJCRkcHGjRsZM2aMPscsIpIE1DnHuK1bt/LAAw/Qvn176tev7zuOiIhEgTrnGLZx40Z27NjBuHHj1DGLiCQRdc4xaufOnYwdO5aOHTuqMIuIJBl1zjFo9erVbN26lccee4xq1ar5jiMiIlGmzjnG5OTkMHHiRE499VQVZhGRJKXOOYYsW7aM9PR0xo8f7zuKiIh4pM45RjjnmDlzJhdddJHvKCIi4pk65xjw7bff8u2335Kamuo7ioiIxAB1zp7l5+ezePFibrzxRt9RREQkRqhz9mjBggUsWLCAv/zlL76jiIhIDFHn7MmuXbvIzMzkz3/+s+8oIiISY9Q5ezBv3jy+/vprBgwY4DuKiIjEIBXnKFuyZAktWrTg3HPP9R1FRERiVExu1n7ttdc48cQTOfHEEznzzDN9xwmbOXPmMG/ePI499ljfUUREJIbFZOf8/vvvk56ezsUXXwzASSedFPef/503bx7du3fnwgsv9B1FRERiXEwWZ4DGjRvz1ltv+Y4RFvPmzWP16tXalC0iIiGJ2eKcKKZOnUrv3r1VmEVEJGQxuc85UXz99dccPHiQBg0a+I4iIiJxRMU5Qp577jmaNGnCb3/7W99RREQkzqg4R8CaNWs48sgjadmype8oIiISh1Scw+zvf/87e/fu5YorrvAdRURE4pSKcxht3bqVzp07c9JJJ/mOIiIicUzFOQycc4wbN45Vq1bRu3dv33FERCTO6aNUleScY926dZx//vl069bNdxwREUkA6pwrwTnHQw89xKZNm1SYRUQkbNQ5V1BBQQFff/01t956K61atfIdR0REEog65wp66KGHSElJUWEWEZGwU+dcTvn5+fz73/9m0KBB1KpVy3ccERFJQOqcy+mxxx6jY8eOKswiIhIx6pxDdPDgQaZMmcKAAQMwM99xREQkgalzDtErr7xC7969VZhFRCTi1DmX4cCBA4wdO5YRI0aoMIuISFSocy5FQUEB8+bN4/bbb1dhFhGRqFFxLsH+/fu59957Of/882nRooXvOCIikkRUnIuRmZnJ0qVLGT58ONWrV/cdR0REkoyKcxG7du1i4MCBdO7cmcaNG/uOIyIiSUgHhBWyY8cONmzYwOjRozniiCN8xxERkSSlzjkoIyOD+++/n3bt2tGgQQPfcUREJImpcwa2bNnCli1bGDduHHXr1vUdR0REklzSd8579+5l1KhRdOrUSYVZRERiQlJ3zmvXrmXdunU89thjVKtWzXccERERIIk757y8PCZOnMhpp52mwiwiIjElKTvnFStW8P333zN27FjfUURERH4m6Tpn5xwzZ87k0ksv9R1FRESkWEnVOS9evJjPPvuM/v37+44iIiJSoqTpnPPy8li8eDF9+/b1HUVERKRUSdE5f/nll3zwwQekpqb6jiIiIlKmhO+cMzIyyMrKYuDAgb6jiIiIhCShi/OHH37IM888Q8+ePXU9ZhERiRsJW5wXL15Ms2bNGDx4sO8oIiIi5RIT+5yzsrL4/e9/z6pVq2jQoAHLli2r1HWU586dy6JFi7j33nvDmFJERCQ6YqI4r1q1in/961+0adOGBg0a0LlzZ3r16lWhx5o7dy4nn3wy5513XnhDioiIRElMFOdDbrnlFkaMGFHhn//4449JT09XYRYRkbgWU8W5MqZNm8Y555xDjx49fEcRERGplIQ4IGzJkiVkZWVx1FFH+Y4iIiJSaXFfnF944QVq1arFjTfe6DuKiIhIWMR1cd60aRN169alffv2vqOIiIiETdwW54kTJ7Jp0yauuuoq31FERETCKi6Lc0ZGBh06dKB79+6+o4iIiIRd3BXnxx57jKVLl3LBBRf4jiIiIhIRcfNRKucca9eupWfPnnTr1s13HBERkYiJi87ZOcfo0aNZv369CrOIiCS8mO+cnXN88cUX3HzzzbRo0cJ3HBERkYiL+c559OjRpKSkqDCLiEjSiNnOuaCggBkzZtC/f39q1qzpO46IiEjUxGzn/OSTT9KpUycVZhERSTohFWcz+7WZLTezdDMbXMxyM7P/F1y+yMxOrWiggwcP8tRTT3HPPfdwwgknVPRhRERE4laZxdnMUoCngIuA44Drzey4IsMuAjoGv/oBEysaaOrUqVx44YWYWUUfQkREJK6F0jmfBqQ751Y553KB14HLioy5DHjRBSwAGphZs/KGmTdvHtdddx3HHHNMeX9UREQkYYRSnFsA6wvd3hC8r7xjytStWzeqVInZ3eAiIiJREcrR2sVtX3YVGIOZ9SOw2ZumTZuSlpYGQFZWFmPHjqV58+Y/3SfhtX//fs1tBGl+I0dzG1ma38ipzNyGUpw3AK0K3W4JbKrAGJxzk4HJAN27d3e9evX6adnFF19MWloahe+T8NHcRpbmN3I0t5Gl+Y2cysxtKNuQvwQ6mlk7M6sOXAfMLDJmJnBj8KjtM4A9zrnNFUokIiKS5MrsnJ1zeWZ2NzAHSAGmOOeWmNkdweWTgNnAxUA6kAXcErnIIiIiic2c+9mu4eg8sdl2YG2RuxsBGR7iJAPNbWRpfiNHcxtZmt/IKW5u2zjnGpf1g96Kc3HM7CvnXHffORKR5jayNL+Ro7mNLM1v5FRmbvW5JRERkRij4iwiIhJjYq04T/YdIIFpbiNL8xs5mtvI0vxGToXnNqb2OYuIiEjsdc4iIiJJL+rFOZqXn0xGIczv74LzusjMPjWzk33kjEdlzW2hcb8ws3wzuyqa+eJdKPNrZr3M7FszW2Jm86OdMV6F8LpQ38zeMbPvgnOrc1WEyMymmNk2M/u+hOUVq2nOuah9ETiJyUqgPVAd+A44rsiYi4F3CZyv+wzg82hmjOevEOf3LKBh8PuLNL/hm9tC4+YRODHPVb5zx8tXiOtuA2Ap0Dp4u4nv3PHwFeLcDgXGBb9vDOwEqvvOHg9fwK+AU4HvS1heoZoW7c45apefTFJlzq9z7lPn3K7gzQUEzoMuZQtl3QW4B3gL2BbNcAkglPn9LTDdObcOwDmnOQ5NKHPrgHpmZkBdAsU5L7ox45Nz7kMC81WSCtW0aBfnqF1+MkmVd+5uI/COTspW5tyaWQvgCmBSFHMlilDW3U5AQzNLM7OFZnZj1NLFt1Dm9kmgC4ELFi0G/uycK4hOvIRXoZoWylWpwilsl5+UYoU8d2Z2DoHi3COiiRJHKHP7BDDIOZcfaECkHEKZ36pAN+A8oBbwmZktcM79GOlwcS6Uub0Q+BY4F+gAvG9mHznn9kY6XBKoUE2LdnEO2+UnpVghzZ2ZnQQ8C1zknNsRpWzxLpS57Q68HizMjYCLzSzPOTcjOhHjWqivDRnOuUwg08w+BE4GVJxLF8rc3gKMdYGdpOlmthroDHwRnYgJrUI1LdqbtXX5ycgqc37NrDUwHbhBPuwmPAAAANlJREFUHUe5lDm3zrl2zrm2zrm2wDTgLhXmkIXy2vA2cLaZVTWz2sDpwA9RzhmPQpnbdQS2SGBmTYFjgVVRTZm4KlTToto5O11+MqJCnN/7gaOAfwQ7vDynk96XKcS5lQoKZX6dcz+Y2X+ARUAB8KxzrtiPr8j/hLjuPgy8YGaLCWyGHeSc05WqQmBmrwG9gEZmtgEYAVSDytU0nSFMREQkxugMYSIiIjFGxVlERCTGqDiLiIjEGBVnERGRGKPiLCIiEmNUnEVERGKMirOIiEiMUXEWERGJMf8fFWq2nceKX+UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
